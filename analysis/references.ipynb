{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the structure of the references extracted by `extract_references.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_refs = json.load(open('../data/json/references/edoc.json'))\n",
    "tu_refs = json.load(open('../data/json/references/depositonce.json'))\n",
    "fu_refs = json.load(open('../data/json/references/refubium.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu = json.load(open('../data/json/dim/edoc/relevant_data.json'))\n",
    "tu = json.load(open('../data/json/dim/depositonce/relevant_data.json'))\n",
    "fu = json.load(open('../data/json/dim/refubium/relevant_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 7433, 14449, 22459)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hu_refs), len(tu_refs), len(fu_refs), len(hu_refs) + len(tu_refs) + len(fu_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many documents have references, in total and per repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TU: 7433 of 7438 docs have references (1.0)\n",
      "HU: 577 of 7497 docs have references (0.08)\n",
      "TU: 14449 of 14464 docs have references (1.0)\n"
     ]
    }
   ],
   "source": [
    "print(f'TU: {len(tu_refs)} of {len(tu)} docs have references ({round(len(tu_refs)/len(tu), 2)})')\n",
    "print(f'HU: {len(hu_refs)} of {len(hu)} docs have references ({round(len(hu_refs)/len(hu), 2)})')\n",
    "print(f'TU: {len(fu_refs)} of {len(fu)} docs have references ({round(len(fu_refs)/len(fu), 2)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 22459 of 29399 docs have references (0.76)\n"
     ]
    }
   ],
   "source": [
    "total_refs_cnt = len(tu_refs) + len(hu_refs)+ len(fu_refs)\n",
    "print(f'Total: {total_refs_cnt} of {len(tu)+len(hu)+len(fu)} docs have references ({round(total_refs_cnt/(len(tu)+len(hu)+len(fu)), 2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do edoc documents seldom have references?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oai:edoc.hu-berlin.de:18452/10114',\n",
       " 'oai:edoc.hu-berlin.de:18452/22862.2',\n",
       " 'oai:edoc.hu-berlin.de:18452/23133',\n",
       " 'oai:edoc.hu-berlin.de:18452/20685',\n",
       " 'oai:edoc.hu-berlin.de:18452/18014']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hu_empty = set(hu.keys()) - set(hu_refs.keys())\n",
    "random.sample(hu_empty, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logs there seems to be some errors: syntax errors and mismatched tags. I assume they belong to refubium. How many IDs are missing in the log, i.e. they were not parsed correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = open('../logs/extractrefs_1636620650.log').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2374"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ids = []\n",
    "parsed_ids = []\n",
    "for id in hu:\n",
    "  number = ' ' + id.split('/')[-1] + ' '\n",
    "  if number not in log:\n",
    "    missing_ids.append(id)\n",
    "  else:\n",
    "    parsed_ids.append(id)\n",
    "len(missing_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the types of the documents that were not parsed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doctoralthesis': 815,\n",
       " 'article': 608,\n",
       " 'book': 627,\n",
       " 'report': 7,\n",
       " 'conferenceobject': 185,\n",
       " 'bookpart': 48,\n",
       " 'workingpaper': 39,\n",
       " 'masterthesis': 38,\n",
       " 'periodicalpart': 2,\n",
       " 'bachelorthesis': 4,\n",
       " 'studythesis': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hu_types = json.load(open('../data/json/dim/edoc/relevant_types.json'))\n",
    "doc_types = {}\n",
    "for id in missing_ids:\n",
    "  doc_type = hu_types[id]\n",
    "  if doc_type in doc_types:\n",
    "    doc_types[doc_type] += 1\n",
    "  else:\n",
    "    doc_types[doc_type] = 1\n",
    "doc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oai:edoc.hu-berlin.de:18452/16948',\n",
       " 'oai:edoc.hu-berlin.de:18452/22301',\n",
       " 'oai:edoc.hu-berlin.de:18452/22161',\n",
       " 'oai:edoc.hu-berlin.de:18452/19707',\n",
       " 'oai:edoc.hu-berlin.de:18452/22420']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(missing_ids, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't find the reason why some edoc articles were not parsed successfully. I am running it again and will investigate it further afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many references are there on average, per repository and in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU avg.: 169.28\n",
      "TU avg.: 151.7\n",
      "FU avg.: 158.91\n",
      "Total avg.: 156.79\n"
     ]
    }
   ],
   "source": [
    "hu_total, tu_total, fu_total = 0, 0, 0\n",
    "for refs in hu_refs.values():\n",
    "  hu_total += len(refs)\n",
    "for refs in tu_refs.values():\n",
    "  tu_total += len(refs)\n",
    "for refs in fu_refs.values():\n",
    "  fu_total += len(refs)\n",
    "print(f'HU avg.: {round(hu_total/len(hu_refs), 2)}')\n",
    "print(f'TU avg.: {round(tu_total/len(tu_refs), 2)}')\n",
    "print(f'FU avg.: {round(fu_total/len(fu_refs), 2)}')\n",
    "total = hu_total + tu_total + fu_total\n",
    "print(f'Total avg.: {round(total/(len(hu_refs)+len(tu_refs)+len(fu_refs)), 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems like a lot. Theses are surely to blame for these large averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theses\n",
      "HU avg.: 322.94\n",
      "TU avg.: 227.66\n",
      "FU avg.: 234.56\n",
      "Total avg.: 815030.95\n",
      "Publications\n",
      "HU avg.: 77.33\n",
      "TU avg.: 91.94\n",
      "FU avg.: 121.16\n",
      "Total avg.: 410449.48\n"
     ]
    }
   ],
   "source": [
    "hu_types = json.load(open('../data/json/dim/edoc/relevant_types.json'))\n",
    "tu_types = json.load(open('../data/json/dim/depositonce/relevant_types.json'))\n",
    "fu_types = json.load(open('../data/json/dim/refubium/relevant_types.json'))\n",
    "hu_theses, tu_theses, fu_theses = [], [], []\n",
    "hu_publications, tu_publications, fu_publications = [], [], []\n",
    "for id in hu_refs:\n",
    "  refs = hu_refs[id]\n",
    "  doc_type = hu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    hu_theses.append(len(refs))\n",
    "  else:\n",
    "    hu_publications.append(len(refs))\n",
    "for id in tu_refs:\n",
    "  refs = tu_refs[id]\n",
    "  doc_type = tu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    tu_theses.append(len(refs))\n",
    "  else:\n",
    "    tu_publications.append(len(refs))\n",
    "for id in fu_refs:\n",
    "  refs = fu_refs[id]\n",
    "  doc_type = fu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    fu_theses.append(len(refs))\n",
    "  else:\n",
    "    fu_publications.append(len(refs))\n",
    "print('Theses')\n",
    "print(f'HU avg.: {round(sum(hu_theses)/len(hu_theses), 2)}')\n",
    "print(f'TU avg.: {round(sum(tu_theses)/len(tu_theses), 2)}')\n",
    "print(f'FU avg.: {round(sum(fu_theses)/len(fu_theses), 2)}')\n",
    "print(f'Total avg.: {round(sum(hu_theses)+sum(tu_theses)+sum(fu_theses)/(len(hu_theses)+len(tu_theses)+len(fu_theses)), 2)}')\n",
    "print('Publications')\n",
    "print(f'HU avg.: {round(sum(hu_publications)/len(hu_publications), 2)}')\n",
    "print(f'TU avg.: {round(sum(tu_publications)/len(tu_publications), 2)}')\n",
    "print(f'FU avg.: {round(sum(fu_publications)/len(fu_publications), 2)}')\n",
    "print(f'Total avg.: {round(sum(hu_publications)+sum(tu_publications)+sum(fu_publications)/(len(hu_publications)+len(tu_publications)+len(fu_publications)), 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afec8bd1b97d7d536c9012edeeda7c68a0e99e84af90a3d324c5b7b0f06b2586"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
