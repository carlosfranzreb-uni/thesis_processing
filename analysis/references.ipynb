{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the structure of the references extracted by `extract_references.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_refs = json.load(open('../data/json/references/edoc.json'))\n",
    "tu_refs = json.load(open('../data/json/references/depositonce.json'))\n",
    "fu_refs = json.load(open('../data/json/references/refubium.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu = json.load(open('../data/json/dim/edoc/relevant_data.json'))\n",
    "tu = json.load(open('../data/json/dim/depositonce/relevant_data.json'))\n",
    "fu = json.load(open('../data/json/dim/refubium/relevant_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7447, 7433, 14449, 29329)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hu_refs), len(tu_refs), len(fu_refs), len(hu_refs) + len(tu_refs) + len(fu_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many documents have references, in total and per repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TU: 7433 of 7438 docs have references (1.0)\n",
      "HU: 7447 of 7497 docs have references (0.99)\n",
      "TU: 14449 of 14464 docs have references (1.0)\n"
     ]
    }
   ],
   "source": [
    "print(f'TU: {len(tu_refs)} of {len(tu)} docs have references ({round(len(tu_refs)/len(tu), 2)})')\n",
    "print(f'HU: {len(hu_refs)} of {len(hu)} docs have references ({round(len(hu_refs)/len(hu), 2)})')\n",
    "print(f'TU: {len(fu_refs)} of {len(fu)} docs have references ({round(len(fu_refs)/len(fu), 2)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 29329 of 29399 docs have references (1.0)\n"
     ]
    }
   ],
   "source": [
    "total_refs_cnt = len(tu_refs) + len(hu_refs)+ len(fu_refs)\n",
    "print(f'Total: {total_refs_cnt} of {len(tu)+len(hu)+len(fu)} docs have references ({round(total_refs_cnt/(len(tu)+len(hu)+len(fu)), 2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many references are there on average, per repository and in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU avg.: 158.62\n",
      "TU avg.: 151.7\n",
      "FU avg.: 158.91\n",
      "Total avg.: 157.01\n"
     ]
    }
   ],
   "source": [
    "hu_total, tu_total, fu_total = 0, 0, 0\n",
    "for refs in hu_refs.values():\n",
    "  hu_total += len(refs)\n",
    "for refs in tu_refs.values():\n",
    "  tu_total += len(refs)\n",
    "for refs in fu_refs.values():\n",
    "  fu_total += len(refs)\n",
    "print(f'HU avg.: {round(hu_total/len(hu_refs), 2)}')\n",
    "print(f'TU avg.: {round(tu_total/len(tu_refs), 2)}')\n",
    "print(f'FU avg.: {round(fu_total/len(fu_refs), 2)}')\n",
    "total = hu_total + tu_total + fu_total\n",
    "print(f'Total avg.: {round(total/(len(hu_refs)+len(tu_refs)+len(fu_refs)), 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems like a lot. Theses are surely to blame for these large averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theses\n",
      "HU avg.: 291.45\n",
      "TU avg.: 227.66\n",
      "FU avg.: 234.56\n",
      "Total avg.: 246.54\n",
      "Publications\n",
      "HU avg.: 84.86\n",
      "TU avg.: 91.94\n",
      "FU avg.: 121.16\n",
      "Total avg.: 105.27\n"
     ]
    }
   ],
   "source": [
    "hu_types = json.load(open('../data/json/dim/edoc/relevant_types.json'))\n",
    "tu_types = json.load(open('../data/json/dim/depositonce/relevant_types.json'))\n",
    "fu_types = json.load(open('../data/json/dim/refubium/relevant_types.json'))\n",
    "hu_theses, tu_theses, fu_theses = [], [], []\n",
    "hu_publications, tu_publications, fu_publications = [], [], []\n",
    "for id in hu_refs:\n",
    "  refs = hu_refs[id]\n",
    "  doc_type = hu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    hu_theses.append(len(refs))\n",
    "  else:\n",
    "    hu_publications.append(len(refs))\n",
    "for id in tu_refs:\n",
    "  refs = tu_refs[id]\n",
    "  doc_type = tu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    tu_theses.append(len(refs))\n",
    "  else:\n",
    "    tu_publications.append(len(refs))\n",
    "for id in fu_refs:\n",
    "  refs = fu_refs[id]\n",
    "  doc_type = fu_types[id]\n",
    "  if 'thesis' in doc_type:\n",
    "    fu_theses.append(len(refs))\n",
    "  else:\n",
    "    fu_publications.append(len(refs))\n",
    "print('Theses')\n",
    "print(f'HU avg.: {round(sum(hu_theses)/len(hu_theses), 2)}')\n",
    "print(f'TU avg.: {round(sum(tu_theses)/len(tu_theses), 2)}')\n",
    "print(f'FU avg.: {round(sum(fu_theses)/len(fu_theses), 2)}')\n",
    "print(f'Total avg.: {round((sum(hu_theses)+sum(tu_theses)+sum(fu_theses))/(len(hu_theses)+len(tu_theses)+len(fu_theses)), 2)}')\n",
    "print('Publications')\n",
    "print(f'HU avg.: {round(sum(hu_publications)/len(hu_publications), 2)}')\n",
    "print(f'TU avg.: {round(sum(tu_publications)/len(tu_publications), 2)}')\n",
    "print(f'FU avg.: {round(sum(fu_publications)/len(fu_publications), 2)}')\n",
    "print(f'Total avg.: {round((sum(hu_publications)+sum(tu_publications)+sum(fu_publications))/(len(hu_publications)+len(tu_publications)+len(fu_publications)), 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the Ids for which there are no references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = {'depositonce': [], 'edoc': [], 'refubium': []}\n",
    "for doc_id in tu:\n",
    "  if doc_id not in tu_refs.keys():\n",
    "    missing['depositonce'].append(doc_id)\n",
    "for doc_id in hu:\n",
    "  if doc_id not in hu_refs.keys():\n",
    "    missing['edoc'].append(doc_id)\n",
    "for doc_id in fu:\n",
    "  if doc_id not in fu_refs.keys():\n",
    "    missing['refubium'].append(doc_id)\n",
    "# json.dump(missing, open('../data/json/references/missing.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What types do these documents belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {\n",
    "  'edoc': json.load(open('../data/json/dim/edoc/relevant_types.json')),\n",
    "  'depositonce': json.load(open('../data/json/dim/depositonce/relevant_types.json')),\n",
    "  'refubium':  json.load(open('../data/json/dim/refubium/relevant_types.json'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doctoralthesis': 18,\n",
       " 'conferenceobject': 8,\n",
       " 'article': 29,\n",
       " 'masterthesis': 5,\n",
       " 'book': 4,\n",
       " 'bookpart': 4,\n",
       " 'workingpaper': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_types = {}\n",
    "for repo in missing.keys():\n",
    "  for id in missing[repo]:\n",
    "    doc_type = types[repo][id]\n",
    "    if doc_type in missing_types:\n",
    "      missing_types[doc_type] += 1\n",
    "    else:\n",
    "      missing_types[doc_type] = 1\n",
    "missing_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oai:depositonce.tu-berlin.de:11303/5131']\n",
      "['oai:edoc.hu-berlin.de:18452/20419', 'oai:edoc.hu-berlin.de:18452/20665', 'oai:edoc.hu-berlin.de:18452/22629']\n",
      "['oai:refubium.fu-berlin.de:fub188/19481']\n"
     ]
    }
   ],
   "source": [
    "print(random.sample(missing['depositonce'], 1))\n",
    "print(random.sample(missing['edoc'], 3))\n",
    "print(random.sample(missing['refubium'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afec8bd1b97d7d536c9012edeeda7c68a0e99e84af90a3d324c5b7b0f06b2586"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
